{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words\n",
    "\n",
    "**In natural language processing, useless words (data), are referred to as stop words.**\n",
    "\n",
    "*we can recognize ourselves that some words carry more meaning than other words. We can also see that some words are just plain useless, and are filler words. We use them in the English language, for example, to sort of \"fluff\" up the sentence so it is not so strange sounding. An example of one of the most common, unofficial, useless words is the phrase \"umm.\"*\n",
    "\n",
    "*We would not want these words taking up space in our database, or taking up valuable processing time. As such, we call these words \"stop words\" because they are useless, and we wish to do nothing with them.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hers', 'did', 'at', 'by', 'against', \"isn't\", 'mustn', \"weren't\", 'here', 'ourselves', 'weren', 'her', 'or', 'shan', 've', 'up', 'from', \"you're\", 'herself', \"wasn't\", 'yourselves', 'should', 'had', \"aren't\", 'more', 'then', 'yourself', 'shouldn', 'above', 's', 'has', 'into', 'it', \"hasn't\", 'off', 'can', 'own', 'over', 'been', 'all', 'be', \"should've\", \"didn't\", 'wasn', 'them', 'any', 'below', 'down', 'were', 'same', 're', 'and', 'where', 'because', 'my', 'wouldn', 'for', 'very', 'as', \"hadn't\", 'isn', \"needn't\", 'most', 'other', 'will', 'mightn', 'the', 'not', 'our', \"couldn't\", \"you'd\", \"you'll\", 'whom', 'both', 'again', 'between', 'so', \"she's\", 'their', \"shouldn't\", 'i', 'too', 'they', 'him', 'before', 'what', 'having', 'to', 'no', 'with', 'himself', 'o', \"it's\", 'that', 'about', 'during', 'm', 'do', 'after', 'don', 'themselves', \"doesn't\", \"don't\", 'she', 'was', 'until', 'have', 'few', 'hasn', \"mustn't\", 'd', 'further', \"haven't\", 'this', 'just', 'doing', 'needn', 'than', \"wouldn't\", 'through', 'your', \"you've\", 'are', 'ours', 'being', 'theirs', 'each', 'll', 'y', 'if', 'those', 'we', 'its', 'his', 'in', 'on', 'under', 'why', 'ma', \"shan't\", 'am', 'doesn', \"won't\", 'me', 'only', 'a', 'yours', 'these', 'won', 'but', 't', 'hadn', 'didn', 'there', 'itself', 'couldn', 'haven', \"mightn't\", 'ain', 'now', 'when', 'while', 'nor', 'you', 'who', 'does', 'of', 'once', 'an', 'how', 'myself', 'out', 'is', 'aren', 'he', 'such', \"that'll\", 'some', 'which'}\n"
     ]
    }
   ],
   "source": [
    "# list of stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "Example = \"\"\"Hello Mr. Maharshi. How are you? Mr. Narendra Modi & Mr. Donald Trump is waiting for you. When will you meet them? They want to collobrate with you for Technology. This is great chance. Let's take it\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = word_tokenize(Example)\n",
    "filtered_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        filtered_words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering\n",
      "['Hello', 'Mr.', 'Maharshi', '.', 'How', 'are', 'you', '?', 'Mr.', 'Narendra', 'Modi', '&', 'Mr.', 'Donald', 'Trump', 'is', 'waiting', 'for', 'you', '.', 'When', 'will', 'you', 'meet', 'them', '?', 'They', 'want', 'to', 'collobrate', 'with', 'you', 'for', 'Technology', '.', 'This', 'is', 'great', 'chance', '.', 'Let', \"'s\", 'take', 'it']\n"
     ]
    }
   ],
   "source": [
    "print('Before filtering')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering\n",
      "['Hello', 'Mr.', 'Maharshi', '.', 'How', '?', 'Mr.', 'Narendra', 'Modi', '&', 'Mr.', 'Donald', 'Trump', 'waiting', '.', 'When', 'meet', '?', 'They', 'want', 'collobrate', 'Technology', '.', 'This', 'great', 'chance', '.', 'Let', \"'s\", 'take']\n"
     ]
    }
   ],
   "source": [
    "print('After filtering')\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
